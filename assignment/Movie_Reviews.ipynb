{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "93tU5i-PdPH5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\szymon\\scoop\\apps\\python310\\current\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import datetime\n",
    "from functools import lru_cache\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "#from google.colab import files\n",
    "import io\n",
    "import random\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from ray.tune.sklearn import TuneGridSearchCV\n",
    "from ray.tune.sklearn import TuneSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 03:04:34,677\tINFO worker.py:1538 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.10.9</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.2.0</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.10.9', ray_version='2.2.0', ray_commit='b6af0887ee5f2e460202133791ad941a41f15beb', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': 'tcp://127.0.0.1:62194', 'raylet_socket_name': 'tcp://127.0.0.1:60674', 'webui_url': '', 'session_dir': 'Z:\\\\Temp\\\\ray\\\\session_2023-02-03_03-04-32_286474_8680', 'metrics_export_port': 64454, 'gcs_address': '127.0.0.1:64715', 'address': '127.0.0.1:64715', 'dashboard_agent_listen_port': 52365, 'node_id': '85badb02824f123148a8a86af44357d2e5335c3d260245064d49198a'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BBdCdMcteQUE"
   },
   "outputs": [],
   "source": [
    "# remove any instance of <...> or numbers\n",
    "REMOVAL_REGEX = re.compile(r\"<.*?>|[0-9]\")\n",
    "SENTIMENT_POS = 1\n",
    "SENTIMENT_NEG = 0\n",
    "SENTIMENT_DICT = {0: \"Negative\", 1: \"Positive\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "GjivWDO1eSXy",
    "outputId": "b50ed008-e62a-40bd-fbfd-a518603f9cd9"
   },
   "outputs": [],
   "source": [
    "# Google Collab\n",
    "#uploaded = files.upload()\n",
    "#all_reviews_df = pd.read_csv(io.BytesIO(uploaded['IMDB Dataset.csv']))\n",
    "# Local Files\n",
    "# Not much point in reading the file if we use pickles anyway\n",
    "all_reviews_df = pd.read_csv(\"./data/IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neVJfVTme7K7"
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I7jzB_WRe894",
    "outputId": "1642faa6-2b1e-4203-c537-b6ce328fda0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews_df.info()\n",
    "all_reviews_df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "B-mxDXTvfreo",
    "outputId": "94cc0645-cd6c-46d9-b443-194acca50830"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "all_reviews_df[\"sentiment\"] = encoder.fit_transform(all_reviews_df[\"sentiment\"])\n",
    "all_reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25000\n",
       "0    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews_df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76fH_ajrfvKi"
   },
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GN3jgsWlfwcc",
    "outputId": "c7040fef-115a-415b-d5f5-87d6807727b1"
   },
   "outputs": [],
   "source": [
    "# Set up SpaCy\n",
    "# You may need to run `python -m pip install 'spacy[transformers,lookups]'`\n",
    "# You may need to run `python -m pip install spacy[cuda-autodetect]\n",
    "# That is assuming you have a CUDA supported GPU (nVidia and AMD apparently support it)\n",
    "# Otherwise it falls back to CPU.\n",
    "# You can also do spacy.require_gpu(), however that will throw an error if it is not supported.\n",
    "# If this returns False and you want it to be True, check if you installed `nvcc`, the Nvidia CUDA compiler.\n",
    "# Also, you need to set the CUDA_PATH environment variable to where you installed the CUDA toolkit\n",
    "# That may be done automatically if you install all components of the nVidia CUDA Toolkit though.\n",
    "# Also, if this returns false, check if you did `python -m pip install cupy`\n",
    "# (this will take a _while_) as you will be compiling some things with nvidia cuda compiler\n",
    "# OR, as an alternative, I think you can do `python -m pip install cupy-wheel` OR\n",
    "# `python -m pip installl cupy-cuda12x`\n",
    "# This might be annoying depending on your GPU driver version.\n",
    "# Actually, on an i7-6700k @4.7GHz, running it on the CPU took 1200 seconds to process 50k reviews\n",
    "# With the help of the GPU, it actually took 1560 seconds. Somehow.\n",
    "# On my laptop with an i7-6820HQ, it took double that time.\n",
    "#print(\"Preferring GPU:\",spacy.prefer_gpu())\n",
    "\n",
    "# You need to run `python -m spacy download en_core_web_sm` or `python -m spacy download en_core_web_lg`\n",
    "# Otherwise you get an error\n",
    "# nlp = spacy.load(\"en_core_web_lg\") # Potentially slower, but with more data.\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "luaAy04Mf4Qq"
   },
   "outputs": [],
   "source": [
    "preprocess_start_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fFHVcPaMf7cZ"
   },
   "outputs": [],
   "source": [
    "# Add some stopwords that weren't caught after preprocessing\n",
    "STOP_WORDS.add(\"s\")\n",
    "#STOP_WORDS.add(\"il\")\n",
    "#STOP_WORDS.add(\"ve\")\n",
    "#STOP_WORDS.add(\"ll\")\n",
    "#STOP_WORDS.add(\"t\")\n",
    "# Potentially crucial, but was not done initially.\n",
    "# The pickled reviews were pre-processed without calling this, therefore some of the reviews\n",
    "# Can be misclassified as they are missing these words.\n",
    "STOP_WORDS.remove(\"not\")\n",
    "STOP_WORDS.remove(\"no\")\n",
    "\n",
    "@lru_cache(maxsize=51200)\n",
    "def is_alpha_cached(token):\n",
    "    return token.is_alpha\n",
    "\n",
    "# Take in a row from a pandas dataframe\n",
    "# And return a list of lemmatized words with no stop words, numbers, etc.\n",
    "\n",
    "# We can't really create a cache here.\n",
    "# As all reviews will be different.\n",
    "# @lru_cache(maxsize=51200)\n",
    "# I've noticed that preprocessing removes words like `not` which is not optimal.\n",
    "# We could have removed `not` from STOP_WORDS.\n",
    "def preprocess_review(review):\n",
    "    review = REMOVAL_REGEX.sub(\" \", review.lower())\n",
    "    doc = nlp(review)\n",
    "    # return \" \".join(w.lemma_ for w in doc if (w.text not in STOP_WORDS and w.lemma_ not in STOP_WORDS) and is_alpha_cached(w))\n",
    "    return \" \".join(w.lemma_ for w in doc if ((w.text not in STOP_WORDS) and is_alpha_cached(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YPmKAwUAf-qT",
    "outputId": "de9105ef-54e4-4ff1-f987-4b7e66cb26b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading positive reviews from pickle\n",
      "Loading negative reviews from pickle\n"
     ]
    }
   ],
   "source": [
    "# This step takes a **long** time (around 30-35 minutes on my machine.)\n",
    "# Becasue of that, I have included the pickle file which can be used instead\n",
    "PICKLE_POS = \"./processed_positive_reviews.pickle\"\n",
    "PICKLE_NEG = \"./processed_negative_reviews.pickle\"\n",
    "if os.path.isfile(PICKLE_POS):\n",
    "    with open(PICKLE_POS, \"rb\") as pickle_file:\n",
    "        print(\"Loading positive reviews from pickle\")\n",
    "        processed_positive_reviews = pickle.load(pickle_file)\n",
    "else:\n",
    "    print(\"Processing positive reviews from scratch\")\n",
    "    processed_positive_reviews = [preprocess_review(review) for _index, (review, sentiment) in all_reviews_df.iterrows() if sentiment == SENTIMENT_POS]\n",
    "    with open(PICKLE_POS, \"wb\") as pickle_file:\n",
    "        print(\"Writing positive reviews to pickle\")\n",
    "        pickle.dump(processed_positive_reviews, pickle_file)\n",
    "    \n",
    "if os.path.isfile(PICKLE_NEG):\n",
    "    with open(PICKLE_NEG, \"rb\") as pickle_file:\n",
    "        print(\"Loading negative reviews from pickle\")\n",
    "        processed_negative_reviews = pickle.load(pickle_file)\n",
    "else:\n",
    "    print(\"Processing negative reviews from scratch\")\n",
    "    processed_negative_reviews = [preprocess_review(review) for _index, (review, sentiment) in all_reviews_df.iterrows() if sentiment == SENTIMENT_NEG]\n",
    "    with open(PICKLE_NEG, \"wb\") as pickle_file:\n",
    "        print(\"Writing positive reviews to pickle\")\n",
    "        pickle.dump(processed_negative_reviews, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample processed positive review:\n",
      " reviewer mention watch oz episode hook right exactly happen thing strike oz brutality unflinche scene violence set right word trust faint hearted timid pull punch regard drug sex violence hardcore classic use word call oz nickname give oswald maximum security state penitentary focus mainly emerald city experimental section prison cell glass front face inward privacy high agenda em city home aryan muslim gangsta latinos christians italian irish scuffle death stare dodgy dealing shady agreement far away main appeal fact go show dare forget pretty picture paint mainstream audience forget charm forget romance oz mess episode see strike nasty surreal ready watch develop taste oz get accustomed high level graphic violence violence injustice crooked guard sell nickel inmate kill order away mannered middle class inmate turn prison bitch lack street skill prison experience watch oz comfortable uncomfortable viewing that touch dark \n",
      "----\n",
      "Sample processed negative review:\n",
      " basically family little boy jake think zombie closet parent fight time movie slow soap opera suddenly jake decide rambo kill zombie ok go film decide thriller drama drama movie watchable parent divorce argue like real life jake closet totally ruin film expect boogeyman similar movie instead watch drama meaningless thriller spot play parent descent dialog shot jake ignore \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample processed positive review:\\n\", processed_positive_reviews[0], \"\\n----\")\n",
    "print(\"Sample processed negative review:\\n\", processed_negative_reviews[0], \"\\n----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000, 25000, 25000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We actually need to split the data 50/50\n",
    "# To ensure that we have an even split of positive/negative reviews for training/testing\n",
    "# We will split the data manually and then shuffle it.\n",
    "SPLIT = 12500\n",
    "\n",
    "random.shuffle(processed_positive_reviews)\n",
    "random.shuffle(processed_negative_reviews)\n",
    "\n",
    "reviews_train = processed_positive_reviews[:SPLIT] + processed_negative_reviews[:SPLIT]\n",
    "sentiments_train = [SENTIMENT_POS] * SPLIT + [SENTIMENT_NEG] * SPLIT\n",
    "\n",
    "reviews_test = processed_positive_reviews[SPLIT:25000] + processed_negative_reviews[SPLIT:25000]\n",
    "sentiments_test = [SENTIMENT_POS] * SPLIT + [SENTIMENT_NEG] * SPLIT\n",
    "\n",
    "# There is no need to shuffle it as train_test_split does it for us.\n",
    "\n",
    "all_reviews = processed_positive_reviews + processed_negative_reviews\n",
    "all_labels = [SENTIMENT_POS] * len(processed_positive_reviews) + [SENTIMENT_NEG] * len(processed_negative_reviews)\n",
    "\n",
    "len(reviews_train), len(reviews_test), len(sentiments_train), len(sentiments_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample train review:\n",
      " kid take movie love child age year give star emma roberts adorable title role expect generation robert future expose like britney spear lindsay lohan paris hilton refreshing girl look like work street enjoy see support cast include tate donovan rachel leigh cook barry bostwick monica parker cameo bruce willis final takeaway cute film note read book series comment base merit film \n",
      "Sentiment: 1 \n",
      "---\n",
      "Sample test review:\n",
      " james corbett autobiography roar crowd starting point lively remember fictionalize biography author heavyweight champion world succeed john sullivan turn century event narrative depict corbett brash likable intelligent young man conquest world boxing social prejudice time consider merely son irish immigrant lowly bank teller surprise take hour exciting amusing screen time prove compeer wrong bank teller film open wangle invitation sporting club fall love beautiful snobbish girl quarrel live home brawl clan corbett fight defeat club good professional fighter borough embarrass finally decide famous fight set road friend act manager trainer despite near setback win bout attract attention come home pursue girl contrive annoy boston strongboy mighty john sullivan enter bar claim lick man world believe win bout sullivan corbett dub gentleman jim gracious manner patrician appearance surprise move dance range negate furious sullivan power film fine scene come beat sullivan come congratulate corbett new champion rise moment tell sullivan year different show admiration respect get girl result performance end film visit parent manager able tell world corbett film attractive consistent style flashy script write veteran horace mccoy vincent lawrence corbett novel sidney hickox cinematography period set decoration clarence steensen art direction ted smith heinz roemheld music milo anderson gown film ably direct action film specialist raoul walsh flynn like work walsh care director work michael curtiz cast ward bond john sullivan good performance lovely alexis smith bit spotty intelligent girl corbett love able errol flynn corbett young man relish playing later say favorite role period jack carson manager alan hale charismatic father john loder rich foe william frawley minor watson madeleine lebeau rhys williams arthur shields dorothy vaughn mike mazurki enjoyable proceeding hard logic light hearted fun movie maker generate well like sport biography film standard enjoyable \n",
      "Sentiment: 1 \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample train review:\\n\", reviews_train[0], \"\\nSentiment:\", sentiments_train[0], \"\\n---\")\n",
    "print(\"Sample test review:\\n\", reviews_test[0], \"\\nSentiment:\", sentiments_test[0], \"\\n---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33vfBf-DgEB6",
    "outputId": "f89837c7-91ee-4e8e-aadd-1f674fd0a490"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing the data took:  0.171816\n"
     ]
    }
   ],
   "source": [
    "print(\"Pre-processing the data took: \", (datetime.datetime.now() - preprocess_start_time).total_seconds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IryQRrwlgHJd"
   },
   "source": [
    "## TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "r3K9KkmygIn6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TF-IDF Vectorizer from pickle\n"
     ]
    }
   ],
   "source": [
    "PICKLE_TFIDF_VECT = \"./tfidf_vectorizer.pickle\"\n",
    "\n",
    "if os.path.isfile(PICKLE_TFIDF_VECT):\n",
    "    with open(PICKLE_TFIDF_VECT, \"rb\") as pickle_file:\n",
    "        print(\"Loading TF-IDF Vectorizer from pickle\")\n",
    "        tfidf_vectorizer = pickle.load(pickle_file)\n",
    "    tfidf_features = tfidf_vectorizer.transform(reviews_train)\n",
    "else:\n",
    "    print(\"Creating tf-idf vectorizer from scratch\")\n",
    "    # It turns out that tfidfVectorizer can actually preprocess our input\n",
    "    # It might be easier to do that than using spacy\n",
    "    # However I did not explore the potential performance difference\n",
    "    # I wonder what the best value for this is\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=100)\n",
    "    tfidf_features = tfidf_vectorizer.fit_transform(reviews_train)\n",
    "    with open(PICKLE_TFIDF_VECT, \"wb\") as pickle_file:\n",
    "        print(\"Writing TF-IDF Vectorizer to pickle\")\n",
    "        pickle.dump(tfidf_vectorizer, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigram Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Unigram Vectorizer from pickle\n"
     ]
    }
   ],
   "source": [
    "PICKLE_UNIGRAM_VECT = \"./unigram_vectorizer.pickle\"\n",
    "\n",
    "if os.path.isfile(PICKLE_UNIGRAM_VECT):\n",
    "    with open(PICKLE_UNIGRAM_VECT, \"rb\") as pickle_file:\n",
    "        print(\"Loading Unigram Vectorizer from pickle\")\n",
    "        unigram_vectorizer = pickle.load(pickle_file)\n",
    "    unigram_features = unigram_vectorizer.transform(reviews_train)\n",
    "else:\n",
    "    print(\"Creating unigram vectorizer from scratch\")\n",
    "    unigram_vectorizer = CountVectorizer(ngram_range=(1, 1), max_features=10000)\n",
    "    unigram_features = unigram_vectorizer.fit_transform(reviews_train)\n",
    "    with open(PICKLE_UNIGRAM_VECT, \"wb\") as pickle_file:\n",
    "        print(\"Writing unigram vectorizer to pickle\")\n",
    "        pickle.dump(unigram_vectorizer, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Bigram Vectorizer from pickle\n"
     ]
    }
   ],
   "source": [
    "PICKLE_BIGRAM_VECT = \"./bigram_vectorizer.pickle\"\n",
    "\n",
    "if os.path.isfile(PICKLE_BIGRAM_VECT):\n",
    "    with open(PICKLE_BIGRAM_VECT, \"rb\") as pickle_file:\n",
    "        print(\"Loading Bigram Vectorizer from pickle\")\n",
    "        bigram_vectorizer = pickle.load(pickle_file)\n",
    "    bigram_features = bigram_vectorizer.transform(reviews_train)\n",
    "else:\n",
    "    print(\"Creating bigram vectorizer from scratch\")\n",
    "    bigram_vectorizer = CountVectorizer(ngram_range=(2, 2), max_features=15000)\n",
    "    bigram_features = bigram_vectorizer.fit_transform(reviews_train)\n",
    "    with open(PICKLE_BIGRAM_VECT, \"wb\") as pickle_file:\n",
    "        print(\"Writing bigram vectorizer to pickle\")\n",
    "        pickle.dump(bigram_vectorizer, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigram Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Trigram Vectorizer from pickle\n"
     ]
    }
   ],
   "source": [
    "PICKLE_TRIGRAM_VECT = \"./trigram_vectorizer.pickle\"\n",
    "\n",
    "if os.path.isfile(PICKLE_TRIGRAM_VECT):\n",
    "    with open(PICKLE_TRIGRAM_VECT, \"rb\") as pickle_file:\n",
    "        print(\"Loading Trigram Vectorizer from pickle\")\n",
    "        trigram_vectorizer = pickle.load(pickle_file)\n",
    "    trigram_features = trigram_vectorizer.transform(reviews_train)\n",
    "else:\n",
    "    print(\"Creating trigram vectorizer from scratch\")\n",
    "    trigram_vectorizer = CountVectorizer(ngram_range=(3, 3), max_features=20000)\n",
    "    trigram_features = trigram_vectorizer.fit_transform(reviews_train)\n",
    "    with open(PICKLE_TRIGRAM_VECT, \"wb\") as pickle_file:\n",
    "        print(\"Writing trigram vectorizer to pickle\")\n",
    "        pickle.dump(trigram_vectorizer, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating The Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample TF-IDF processed review:\n",
      "   (0, 87)\t0.39841977055095673\n",
      "  (0, 57)\t0.2995195311612519\n",
      "  (0, 31)\t0.36286292688956506\n",
      "  (0, 16)\t0.521041357497608\n",
      "  (0, 1)\t0.5902509101672396 \n",
      "----\n",
      "Sample Unigram processed review:\n",
      "   (0, 78)\t1\n",
      "  (0, 2924)\t1\n",
      "  (0, 3798)\t1\n",
      "  (0, 4294)\t1\n",
      "  (0, 5861)\t1\n",
      "  (0, 5935)\t1\n",
      "  (0, 6169)\t1\n",
      "  (0, 6838)\t1\n",
      "  (0, 7120)\t1\n",
      "  (0, 9072)\t1\n",
      "  (0, 9099)\t1\n",
      "  (0, 9729)\t1 \n",
      "----\n",
      "Sample Bigram processed review:\n",
      "  \n",
      "----\n",
      "Sample Trigram processed review:\n",
      "  \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "sample_negative_review = \"Horrible. I wanted the movie to end as quickly as possible. Waste of time and money, and the acting was not good either.\"\n",
    "sample_positive_review = \"This movie is great! I really, really loved it. Best movie I experienced in cinemas recently.\"\n",
    "\n",
    "# .transform takes in a list of strings\n",
    "# eg. [\"This movie is banging!\"]\n",
    "\n",
    "print(\"Sample TF-IDF processed review:\\n\", tfidf_vectorizer.transform([sample_negative_review]), \"\\n----\")\n",
    "print(\"Sample Unigram processed review:\\n\", unigram_vectorizer.transform([sample_negative_review]), \"\\n----\")\n",
    "print(\"Sample Bigram processed review:\\n\", bigram_vectorizer.transform([sample_negative_review]), \"\\n----\")\n",
    "print(\"Sample Trigram processed review:\\n\", trigram_vectorizer.transform([sample_negative_review]), \"\\n----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These steps can take a few minutes as well.\n",
    "# In the future: Add these into pickles\n",
    "tfidf_vectorized_test_reviews = tfidf_vectorizer.transform(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_vectorized_test_reviews = unigram_vectorizer.transform(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_vectorized_test_reviews = bigram_vectorizer.transform(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_vectorized_test_reviews = trigram_vectorizer.transform(reviews_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_hyperparams(cv_results):\n",
    "    print(\"Best Parameters:\", cv_results.best_params_)\n",
    "    cv_mean_score = cv_results.cv_results_[\"mean_test_score\"]\n",
    "    cv_std_score = cv_results.cv_results_[\"std_test_score\"]\n",
    "    cv_params = cv_results.cv_results_[\"params\"]\n",
    "    for mean, std, params in zip(cv_mean_score, cv_std_score, cv_params):\n",
    "        # The values have a lot of decimal places\n",
    "        print(round(mean, 2), \"\\t+-\\t\", round(std, 2), \"\\tfor\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Train Reviews: 10000\n",
      "Negative Train Reviews: 10000\n",
      "Positive Test Reviews: 2500\n",
      "Negative Test Reviews: 2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20000, 5000, 20000, 5000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Out of the 25k reviews for training, we can do hyperparameter tuning by taking let's say 20k for training, and 5k for testing\n",
    "\n",
    "# I think this can be done in a better way\n",
    "# What I do now is a little funky.\n",
    "\n",
    "# total training reviews = 25k\n",
    "# [12500 * positive] + [12500 * negative]\n",
    "# What we want to do is:\n",
    "# training = [10000 * positive] + [10000 * negative]\n",
    "# testing = [2500 * positive] + [2500 * negative]\n",
    "# Honestly, this should have been implemented in a better data structure than primitive lists.\n",
    "# That's a \"to-do\" for future me.\n",
    "\n",
    "# Keep in mind, the reviews are shuffled, but the order of positive and negative reviews are constant\n",
    "kfold_reviews_train = reviews_train[:10000] + reviews_train[12500:22500]\n",
    "kfold_sentiments_train = sentiments_train[:10000] + sentiments_train[12500:22500]\n",
    "\n",
    "kfold_reviews_test = reviews_train[10000:12500] + reviews_train[22500:25000]\n",
    "kfold_sentiments_test = sentiments_train[10000:12500] + sentiments_train[22500:25000]\n",
    "\n",
    "print(\"Positive Train Reviews:\", len([s for s in kfold_sentiments_train if s == SENTIMENT_POS]))\n",
    "print(\"Negative Train Reviews:\", len([s for s in kfold_sentiments_train if s == SENTIMENT_NEG]))\n",
    "print(\"Positive Test Reviews:\", len([s for s in kfold_sentiments_test if s == SENTIMENT_POS]))\n",
    "print(\"Negative Test Reviews:\", len([s for s in kfold_sentiments_test if s == SENTIMENT_NEG]))\n",
    "\n",
    "len(kfold_reviews_train), len(kfold_reviews_test), len(kfold_sentiments_train), len(kfold_sentiments_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "Naive Bayes does not have any hyper-parameters we can tune."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 0.0001, 'epsilon': 0.1}\n",
      "0.66 \t+-\t 0.01 \tfor {'alpha': 1e-07, 'epsilon': 0.01}\n",
      "0.74 \t+-\t 0.01 \tfor {'alpha': 0.0001, 'epsilon': 0.01}\n",
      "0.69 \t+-\t 0.01 \tfor {'alpha': 0.1, 'epsilon': 0.01}\n",
      "0.62 \t+-\t 0.06 \tfor {'alpha': 1, 'epsilon': 0.01}\n",
      "0.66 \t+-\t 0.02 \tfor {'alpha': 1e-07, 'epsilon': 0.1}\n",
      "0.74 \t+-\t 0.01 \tfor {'alpha': 0.0001, 'epsilon': 0.1}\n",
      "0.68 \t+-\t 0.03 \tfor {'alpha': 0.1, 'epsilon': 0.1}\n",
      "0.51 \t+-\t 0.01 \tfor {'alpha': 1, 'epsilon': 0.1}\n",
      "0.66 \t+-\t 0.03 \tfor {'alpha': 1e-07, 'epsilon': 0.25}\n",
      "0.74 \t+-\t 0.01 \tfor {'alpha': 0.0001, 'epsilon': 0.25}\n",
      "0.67 \t+-\t 0.02 \tfor {'alpha': 0.1, 'epsilon': 0.25}\n",
      "0.67 \t+-\t 0.06 \tfor {'alpha': 1, 'epsilon': 0.25}\n",
      "0.67 \t+-\t 0.01 \tfor {'alpha': 1e-07, 'epsilon': 0.5}\n",
      "0.73 \t+-\t 0.0 \tfor {'alpha': 0.0001, 'epsilon': 0.5}\n",
      "0.69 \t+-\t 0.03 \tfor {'alpha': 0.1, 'epsilon': 0.5}\n",
      "0.57 \t+-\t 0.05 \tfor {'alpha': 1, 'epsilon': 0.5}\n",
      "0.66 \t+-\t 0.01 \tfor {'alpha': 1e-07, 'epsilon': 1}\n",
      "0.73 \t+-\t 0.01 \tfor {'alpha': 0.0001, 'epsilon': 1}\n",
      "0.7 \t+-\t 0.01 \tfor {'alpha': 0.1, 'epsilon': 1}\n",
      "0.65 \t+-\t 0.03 \tfor {'alpha': 1, 'epsilon': 1}\n",
      "Accuracy: 0.7408\n",
      "Confusion Matrix: \n",
      "----\n",
      " [[1758  742]\n",
      " [ 554 1946]] \n",
      "----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.70      0.73      2500\n",
      "           1       0.72      0.78      0.75      2500\n",
      "\n",
      "    accuracy                           0.74      5000\n",
      "   macro avg       0.74      0.74      0.74      5000\n",
      "weighted avg       0.74      0.74      0.74      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes doesn't have any hyper-parameters (actually, it has `alpha`...)\n",
    "# So we start off with SVM\n",
    "hyper_svm = SGDClassifier()\n",
    "hyper_svm_params = {\n",
    "    #\"epsilon\" : [0.01]\n",
    "    \"alpha\": [1e-7, 1e-4, 1e-1, 1],\n",
    "    \"epsilon\": [0.01, 0.1, 0.25, 0.5, 1]\n",
    "    # Used for svm.SVC() and not for SGDClassifier()\n",
    "    #\"kernel\": [\"linear\", \"rbf\"],\n",
    "    #\"C\": [0.1, 1, 2, 5, 10] # How harshly are wrong answers punished\n",
    "}\n",
    "\n",
    "# We can stick n_jobs = -1 here to ensure all CPU cores are used\n",
    "# We can also run these on the GPU with the use_gpu=True flag\n",
    "svm_cv = TuneGridSearchCV(\n",
    "    hyper_svm, hyper_svm_params, early_stopping=True, max_iters=10, use_gpu=True\n",
    ")\n",
    "svm_cv.fit(tfidf_vectorizer.transform(kfold_reviews_train), kfold_sentiments_train)\n",
    "display_hyperparams(svm_cv)\n",
    "# The above svm_cv.best_params will be used in our models later on.\n",
    "\n",
    "# Then see what results we get\n",
    "# This should be in a function. Ah well.\n",
    "svm_hyper_pred = svm_cv.predict(tfidf_vectorizer.transform(kfold_reviews_test))\n",
    "print(\"Accuracy:\", accuracy_score(kfold_sentiments_test, svm_hyper_pred))\n",
    "print(\"Confusion Matrix:\", \"\\n----\\n\", confusion_matrix(kfold_sentiments_test, svm_hyper_pred), \"\\n----\")\n",
    "print(classification_report(kfold_sentiments_test, svm_hyper_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_neighbors': 19}\n",
      "0.67 \t+-\t 0.01 \tfor {'n_neighbors': 7}\n",
      "0.68 \t+-\t 0.01 \tfor {'n_neighbors': 9}\n",
      "0.68 \t+-\t 0.01 \tfor {'n_neighbors': 11}\n",
      "0.69 \t+-\t 0.01 \tfor {'n_neighbors': 13}\n",
      "0.69 \t+-\t 0.01 \tfor {'n_neighbors': 15}\n",
      "0.69 \t+-\t 0.01 \tfor {'n_neighbors': 17}\n",
      "0.69 \t+-\t 0.01 \tfor {'n_neighbors': 19}\n",
      "Accuracy: 0.6894\n",
      "Confusion Matrix: \n",
      "----\n",
      " [[1604  896]\n",
      " [ 657 1843]] \n",
      "----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.64      0.67      2500\n",
      "           1       0.67      0.74      0.70      2500\n",
      "\n",
      "    accuracy                           0.69      5000\n",
      "   macro avg       0.69      0.69      0.69      5000\n",
      "weighted avg       0.69      0.69      0.69      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This can take a few minutes to complete.\n",
    "# If you want, you can skip this. I ran it a few times and it consistently returned 19 as the best value.\n",
    "# That's also mentioned later when running the final model.\n",
    "hyper_knn = KNeighborsClassifier()\n",
    "hyper_knn_params = {\n",
    "    # I deleted 1, 2, 3 and 5 from this list\n",
    "    # That is because I have tested it with 9, and it was better\n",
    "    # Therefore we can reduce the computational complexity a little.\n",
    "    \"n_neighbors\": [7, 9, 11, 13, 15, 17, 19]\n",
    "}\n",
    "\n",
    "knn_cv = TuneGridSearchCV(\n",
    "    hyper_knn, hyper_knn_params, early_stopping=False, max_iters=1\n",
    ")\n",
    "\n",
    "knn_cv.fit(tfidf_vectorizer.transform(kfold_reviews_train), kfold_sentiments_train)\n",
    "display_hyperparams(knn_cv)\n",
    "\n",
    "knn_hyper_pred = knn_cv.predict(tfidf_vectorizer.transform(kfold_reviews_test))\n",
    "print(\"Accuracy:\", accuracy_score(kfold_sentiments_test, knn_hyper_pred))\n",
    "print(\"Confusion Matrix:\", \"\\n----\\n\", confusion_matrix(kfold_sentiments_test, knn_hyper_pred), \"\\n----\")\n",
    "print(classification_report(kfold_sentiments_test, knn_hyper_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Grams\n",
    "As the N-Grams in this project utilise the same model as Naive Bayes, there are no hyper-parameters to tune."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training naive bayes model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes_model = MultinomialNB()\n",
    "print(\"Training naive bayes model...\")\n",
    "naive_bayes_model.fit(tfidf_features, sentiments_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Own Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "# You can run more manual predictions here\n",
    "bayes_pred = naive_bayes_model.predict(tfidf_vectorizer.transform([sample_positive_review, sample_negative_review]))\n",
    "for p in bayes_pred:\n",
    "    print(SENTIMENT_DICT[p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73168\n",
      "[[9001 3499]\n",
      " [3209 9291]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73     12500\n",
      "           1       0.73      0.74      0.73     12500\n",
      "\n",
      "    accuracy                           0.73     25000\n",
      "   macro avg       0.73      0.73      0.73     25000\n",
      "weighted avg       0.73      0.73      0.73     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bayes_predictions = naive_bayes_model.predict(tfidf_vectorized_test_reviews)\n",
    "print(accuracy_score(sentiments_test, bayes_predictions))\n",
    "print(confusion_matrix(sentiments_test, bayes_predictions))\n",
    "print(classification_report(sentiments_test, bayes_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get the best hyper-parameters automatically\n",
    "# If this fails etc. A set of params that I got when running this notebook was:\n",
    "# Best Parameters: {'alpha': 0.0001, 'epsilon': 1}\n",
    "svm_model = SGDClassifier(epsilon=svm_cv.best_params_[\"epsilon\"], alpha=svm_cv.best_params_[\"alpha\"])\n",
    "svm_model.fit(tfidf_features, sentiments_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Own Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n",
      "Positive\n"
     ]
    }
   ],
   "source": [
    "svm_pred = svm_model.predict(tfidf_vectorizer.transform([sample_positive_review, sample_negative_review]))\n",
    "for p in svm_pred:\n",
    "    print(SENTIMENT_DICT[p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74116\n",
      "[[9127 3373]\n",
      " [3098 9402]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74     12500\n",
      "           1       0.74      0.75      0.74     12500\n",
      "\n",
      "    accuracy                           0.74     25000\n",
      "   macro avg       0.74      0.74      0.74     25000\n",
      "weighted avg       0.74      0.74      0.74     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_predictions = svm_model.predict(tfidf_vectorized_test_reviews)\n",
    "print(accuracy_score(sentiments_test, svm_predictions))\n",
    "print(confusion_matrix(sentiments_test, svm_predictions))\n",
    "print(classification_report(sentiments_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=19)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=19)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=19)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get the param automatically after running hyper-parameter tuning\n",
    "# If that fails, let's use 19 as that's the best value I got when I tested it\n",
    "knn_model = KNeighborsClassifier(n_neighbors=knn_cv.best_params_[\"n_neighbors\"])\n",
    "knn_model.fit(tfidf_features, sentiments_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Own Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "knn_pred = knn_model.predict(tfidf_vectorizer.transform([sample_positive_review, sample_negative_review]))\n",
    "for p in knn_pred:\n",
    "    print(SENTIMENT_DICT[p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69552\n",
      "[[8026 4474]\n",
      " [3138 9362]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.64      0.68     12500\n",
      "           1       0.68      0.75      0.71     12500\n",
      "\n",
      "    accuracy                           0.70     25000\n",
      "   macro avg       0.70      0.70      0.69     25000\n",
      "weighted avg       0.70      0.70      0.69     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_predictions = knn_model.predict(tfidf_vectorized_test_reviews)\n",
    "print(accuracy_score(sentiments_test, knn_predictions))\n",
    "print(confusion_matrix(sentiments_test, knn_predictions))\n",
    "print(classification_report(sentiments_test, knn_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram Model\n",
    "Note to self: There is no actual unigram model. We use Naive Bayes for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_model = MultinomialNB()\n",
    "unigram_model.fit(unigram_vectorized_test_reviews, sentiments_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Own Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "unigram_pred = unigram_model.predict(unigram_vectorizer.transform([sample_positive_review, sample_negative_review]))\n",
    "for p in unigram_pred:\n",
    "    print(SENTIMENT_DICT[p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86728\n",
      "[[11005  1495]\n",
      " [ 1823 10677]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87     12500\n",
      "           1       0.88      0.85      0.87     12500\n",
      "\n",
      "    accuracy                           0.87     25000\n",
      "   macro avg       0.87      0.87      0.87     25000\n",
      "weighted avg       0.87      0.87      0.87     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unigram_predictions = unigram_model.predict(unigram_vectorized_test_reviews)\n",
    "print(accuracy_score(sentiments_test, unigram_predictions))\n",
    "print(confusion_matrix(sentiments_test, unigram_predictions))\n",
    "print(classification_report(sentiments_test, unigram_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_model = MultinomialNB()\n",
    "bigram_model.fit(bigram_vectorized_test_reviews, sentiments_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Own Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "bigram_pred = bigram_model.predict(bigram_vectorizer.transform([sample_positive_review, sample_negative_review]))\n",
    "for p in bigram_pred:\n",
    "    print(SENTIMENT_DICT[p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88256\n",
      "[[10829  1671]\n",
      " [ 1265 11235]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88     12500\n",
      "           1       0.87      0.90      0.88     12500\n",
      "\n",
      "    accuracy                           0.88     25000\n",
      "   macro avg       0.88      0.88      0.88     25000\n",
      "weighted avg       0.88      0.88      0.88     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bigram_predictions = bigram_model.predict(bigram_vectorized_test_reviews)\n",
    "print(accuracy_score(sentiments_test, bigram_predictions))\n",
    "print(confusion_matrix(sentiments_test, bigram_predictions))\n",
    "print(classification_report(sentiments_test, bigram_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_model = MultinomialNB()\n",
    "trigram_model.fit(trigram_vectorized_test_reviews, sentiments_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Own Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "trigram_pred = trigram_model.predict(trigram_vectorizer.transform([sample_positive_review, sample_negative_review]))\n",
    "for p in trigram_pred:\n",
    "    print(SENTIMENT_DICT[p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80264\n",
      "[[10887  1613]\n",
      " [ 3321  9179]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.87      0.82     12500\n",
      "           1       0.85      0.73      0.79     12500\n",
      "\n",
      "    accuracy                           0.80     25000\n",
      "   macro avg       0.81      0.80      0.80     25000\n",
      "weighted avg       0.81      0.80      0.80     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trigram_predictions = trigram_model.predict(trigram_vectorized_test_reviews)\n",
    "print(accuracy_score(sentiments_test, trigram_predictions))\n",
    "print(confusion_matrix(sentiments_test, trigram_predictions))\n",
    "print(classification_report(sentiments_test, trigram_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
